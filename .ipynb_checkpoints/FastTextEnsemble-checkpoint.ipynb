{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification via Ensemble of FastText and scikit-learn\n",
    "\n",
    "Text classification is becoming a common solution to many problems in industry today including chatbots, sentiment analysis, document tagging, recommendations, etc. This article will focus on utilizing [scikit-learn](http://scikit-learn.org), a mature machine library in Python, and a relatively new library from Facebook AI Reasearch called [fastText](https://fasttext.cc/).\n",
    "\n",
    "The data we will be using today will be publicly available [reddit](http://reddit.com/) data available [here in a Google BigQuery repository](https://bigquery.cloud.google.com/dataset/fh-bigquery:reddit_posts?pli=1). The data used here is provided in this page's [GitHub repository](https://github.com/victorkwak/FastTextEnsemble) so no need to separately download the data to follow this tutorial and using Google Cloud to download data is out of the scope of this article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "I recommend downloading [Anaconda](https://www.anaconda.com/download/) for the base Python libraries needed for this tutorial. You will also need to download fastText available from their [GitHub repository](https://github.com/facebookresearch/fastText)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data\n",
    "\n",
    "We will be using [pandas](https://pandas.pydata.org/) in order to read in and explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique subreddits in the dataset: 136\n",
      "Number of title posts in dataset: 615825\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357036</th>\n",
       "      <td>LUKS help</td>\n",
       "      <td>2</td>\n",
       "      <td>linuxquestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>Dragons when upgrading from Angular 2.1.x to 2...</td>\n",
       "      <td>5</td>\n",
       "      <td>Angular2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261678</th>\n",
       "      <td>Aruba S3500-24p noise level</td>\n",
       "      <td>0</td>\n",
       "      <td>networking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437806</th>\n",
       "      <td>[Bugs] And yet another bug in the new App Stor...</td>\n",
       "      <td>7</td>\n",
       "      <td>iOSBeta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567615</th>\n",
       "      <td>torvalds/linux has infinite contributors</td>\n",
       "      <td>181</td>\n",
       "      <td>ProgrammerHumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333320</th>\n",
       "      <td>After deleting files, Mac became slow</td>\n",
       "      <td>0</td>\n",
       "      <td>mac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450697</th>\n",
       "      <td>How can I find a URL needle in an internet hay...</td>\n",
       "      <td>1</td>\n",
       "      <td>computerscience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102575</th>\n",
       "      <td>Are there any differences between modern web a...</td>\n",
       "      <td>5</td>\n",
       "      <td>cscareerquestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211682</th>\n",
       "      <td>I had no idea you had to unroot before encrypt...</td>\n",
       "      <td>1</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150866</th>\n",
       "      <td>Dart talk by kevmoo in Seattle Feb 21 (RSVP re...</td>\n",
       "      <td>5</td>\n",
       "      <td>dartlang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  score  \\\n",
       "357036                                          LUKS help      2   \n",
       "952     Dragons when upgrading from Angular 2.1.x to 2...      5   \n",
       "261678                        Aruba S3500-24p noise level      0   \n",
       "437806  [Bugs] And yet another bug in the new App Stor...      7   \n",
       "567615           torvalds/linux has infinite contributors    181   \n",
       "333320              After deleting files, Mac became slow      0   \n",
       "450697  How can I find a URL needle in an internet hay...      1   \n",
       "102575  Are there any differences between modern web a...      5   \n",
       "211682  I had no idea you had to unroot before encrypt...      1   \n",
       "150866  Dart talk by kevmoo in Seattle Feb 21 (RSVP re...      5   \n",
       "\n",
       "                subreddit  \n",
       "357036     linuxquestions  \n",
       "952              Angular2  \n",
       "261678         networking  \n",
       "437806            iOSBeta  \n",
       "567615    ProgrammerHumor  \n",
       "333320                mac  \n",
       "450697    computerscience  \n",
       "102575  cscareerquestions  \n",
       "211682            Android  \n",
       "150866           dartlang  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/cs_subs.csv').dropna().drop_duplicates() #Unzip this data from the zip file included.\n",
    "\n",
    "print('Number of unique subreddits in the dataset:', len(data['subreddit'].unique()))\n",
    "print('Number of title posts in dataset:', data.shape[0])\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are filtering subreddits that have less than 150 posts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = data['subreddit'].value_counts()\n",
    "counts = counts[counts > 150]\n",
    "top_values = list(counts.index)\n",
    "data = data[data['subreddit'].isin(top_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique subreddits after filtering: 117\n",
      "Number of title posts after filtering: 614464\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique subreddits after filtering:', len(data['subreddit'].unique()))\n",
    "print('Number of title posts after filtering:', data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a very skewed dataset. Let's see the average reddit score (upvotes + downvotes) for each subreddit to filter out. I want to do mean and not median since median would just arbitrarily cut the data in half. Hopefully filtering by mean will take relatively larger chunks out of the more popular subreddits than the less popular ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = {}\n",
    "for subreddit in data['subreddit'].unique():\n",
    "    means[subreddit] = data[data['subreddit'] == subreddit]['score'].mean()\n",
    "    \n",
    "filtered = []\n",
    "\n",
    "for subreddit in data['subreddit'].unique():\n",
    "    filtered.append(data.loc[(data['subreddit'] == subreddit) & (data['score'] >= means[subreddit])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Android                6771\n",
       "linuxquestions         3893\n",
       "cscareerquestions      3772\n",
       "learnpython            3060\n",
       "webdev                 2565\n",
       "hackernews             2563\n",
       "iOSBeta                2424\n",
       "Windows10              2338\n",
       "linux4noobs            2274\n",
       "ProgrammerHumor        2182\n",
       "networking             2133\n",
       "linux                  2013\n",
       "windows                2005\n",
       "androiddev             1901\n",
       "javascript             1880\n",
       "learnprogramming       1813\n",
       "softwaregore           1746\n",
       "ios                    1737\n",
       "androidthemes          1630\n",
       "java                   1567\n",
       "chrome                 1548\n",
       "rust                   1466\n",
       "Python                 1464\n",
       "web_design             1361\n",
       "javahelp               1326\n",
       "aws                    1253\n",
       "arduino                1205\n",
       "iOSProgramming         1189\n",
       "mac                    1150\n",
       "csshelp                1100\n",
       "                       ... \n",
       "operabrowser            221\n",
       "mongodb                 197\n",
       "macapps                 189\n",
       "windowsinsiders         189\n",
       "LanguageTechnology      181\n",
       "softwaredevelopment     178\n",
       "djangolearning          173\n",
       "watchOSBeta             149\n",
       "browsers                142\n",
       "itsaunixsystem          138\n",
       "symfony                 124\n",
       "lua                     121\n",
       "nginx                   120\n",
       "windows8                119\n",
       "haskellquestions        117\n",
       "rubyonrails             117\n",
       "programmerreactions     117\n",
       "dartlang                103\n",
       "Meteor                  101\n",
       "redis                    86\n",
       "Julia                    82\n",
       "npm                      74\n",
       "erlang                   72\n",
       "zsh                      69\n",
       "OSXTweaks                67\n",
       "DatabaseHelp             59\n",
       "MaterialDesign           51\n",
       "d3js                     49\n",
       "cprogramming             48\n",
       "reviewmycode             44\n",
       "Name: subreddit, Length: 117, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = pd.concat(filtered)\n",
    "filtered_data['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting data into train (60%), val (20%), and test (20%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58960,)\n",
      "(19654,)\n",
      "(19654,)\n",
      "(58960,)\n",
      "(19654,)\n",
      "(19654,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = filtered_data['title']\n",
    "y = filtered_data['subreddit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=17)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=31)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data['subreddit'])\n",
    "\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1), stop_words='english')\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_val_vectors = vectorizer.transform(X_val)\n",
    "X_test_vectors = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def top_n_accuracy(y_true, probs, n=5):\n",
    "    top_n_list = []\n",
    "    for prob in probs:\n",
    "        top_n_list.append(np.argsort(-prob)[:n])\n",
    "    predictions = []\n",
    "    for prediction, top_n in zip(y_true, top_n_list):\n",
    "        predictions.append(int(prediction in top_n))\n",
    "    return np.sum(predictions) / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "svm = SVC(kernel='linear', decision_function_shape='ovr', C=0.2, max_iter=1000, probability=True)\n",
    "svm.fit(X_train_vectors, y_train)\n",
    "svm_predictions = svm.predict(X_val_vectors)\n",
    "\n",
    "print(accuracy_score(y_val, svm_predictions))\n",
    "# print(classification_report(y_val, svm_predictions))\n",
    "\n",
    "_,_, svm_f1, _ = precision_recall_fscore_support(y_val, svm_predictions, beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "\n",
    "def format_for_fastext(X, y, filename):\n",
    "    prefix = '__label__'\n",
    "    f = open(''.join(['data/', filename]), 'w')\n",
    "    for title, label in zip(X, y):\n",
    "        title = title.lower()\n",
    "        tokens = utils.simple_preprocess(title)\n",
    "#         tokens = [token for token in tokens if token not in ENGLISH_STOP_WORDS]\n",
    "        f.write(''.join([prefix, str(label), ' ', ' '.join(tokens), '\\n']))\n",
    "    f.close()\n",
    "    \n",
    "format_for_fastext(X_train, y_train, 'reddit_fasttext_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fasttext(y, X, classifier, n=1):\n",
    "    match = []\n",
    "    for true, string in zip(y, X):\n",
    "        predictions = list(classifier.predict(string, n)[0])\n",
    "        for i in range(n):\n",
    "            predictions[i] = int(predictions[i].split('__label__')[1])\n",
    "        match.append(int(true in predictions))\n",
    "    return np.array(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36704996438384047"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastText\n",
    "\n",
    "classifier = fastText.train_supervised(input='data/reddit_fasttext_train.txt',\n",
    "                                 lr=0.1,\n",
    "                                 epoch=30,\n",
    "                                 dim=64,\n",
    "                                 minn=2,\n",
    "                                 maxn=5\n",
    "                                )\n",
    "\n",
    "correct = test_fasttext(y_val, X_val, classifier)\n",
    "correct.sum() / y_val.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
